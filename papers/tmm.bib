@article{Liang2016,
abstract = {We introduce a visual analytics method to analyze eye-tracking data and saliency models for dynamic stimuli, such as video or animated graphics. The focus lies on the analysis of the different performance of saliency models in contrast to human observers to identify trends in the general viewing behavior, including time sequences of attentional synchrony and objects with a strong attentional focus. By using a space-time cube visualization in combination with clustering, the dynamic stimuli and associated eye gazes as well as the attention maps from saliency models can be analyzed in a static three-dimensional representation. We propose algorithms to keep the appearance of the computer's attention data in line with the human's eye-tracking data. The analytical process is supported by multiple coordinated views that allow the user to focus on different aspects of spatial and temporal information in eye gaze data and saliency map. By comparing attention data from both human and computer incorporated with the spatiotemporal characteristics, we are able to find the different patterns within human and computer algorithms. We list our key findings to help developing better saliency detection algorithms.},
author = {Liang, Haoran and Liang, Ronghua and Sun, Guodao},
doi = {10.1109/TMM.2016.2613681},
isbn = {1520-9210 VO - 18},
issn = {15209210},
journal = {IEEE Transactions on Multimedia},
keywords = {Saliency model,spatiotemporal analysis,visualization},
number = {11},
pages = {2271--2281},
title = {{Looking Into Saliency Model via Space-Time Visualization}},
volume = {18},
year = {2016}
}
